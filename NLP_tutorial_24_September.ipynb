{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_tutorial_24_September.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhyQsfg8pZ26"
      },
      "source": [
        "# **Hands-on Scikit-Learn**\n",
        "\n",
        "# **Word Counts with CountVectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RghXFIisn_XA"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# list of text documents\n",
        "text = [\"The quick brown fox jumped over the lazy dog.\"]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFe_eaPwqUAY"
      },
      "source": [
        "## **Create the transform**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBH_PYr6p9NZ"
      },
      "source": [
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6ohTVuAqanK"
      },
      "source": [
        "##**Tokenize and build vocabulary and print it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMEs3F_RqXjC",
        "outputId": "b6e2267a-97e5-410c-adbc-c476541a63c0"
      },
      "source": [
        "vectorizer.fit(text)\n",
        "print(vectorizer.vocabulary_)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 7, 'quick': 6, 'brown': 0, 'fox': 2, 'jumped': 3, 'over': 5, 'lazy': 4, 'dog': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crgenzIDqk4d"
      },
      "source": [
        "##**Encode the document and print details**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeRFNDMRqioJ",
        "outputId": "e348e1fa-d106-4432-e84c-296e38e06a71"
      },
      "source": [
        "vector = vectorizer.transform(text)\n",
        "\n",
        "print(vector.shape)\n",
        "print(type(vector))\n",
        "print(vector.toarray())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 8)\n",
            "<class 'scipy.sparse.csr.csr_matrix'>\n",
            "[[1 1 1 1 1 1 1 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql-lPLHrq50V"
      },
      "source": [
        "##**Encode another document and print the details**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgOApTBlqp0g",
        "outputId": "d2db7006-0cde-40d8-bb42-36fa06667cac"
      },
      "source": [
        "text2 = [\"the puppy\"]\n",
        "vector = vectorizer.transform(text2)\n",
        "print(vector.toarray())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 0 0 0 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_Tg2XttrEvs"
      },
      "source": [
        "#**Word Frequencies with TfidfVectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gVk4zDnq5V8",
        "outputId": "9b6fa48c-05e6-419b-d9e6-8e23560c794a"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# list of text documents\n",
        "text = [\"The quick brown fox jumped over the lazy dog.\", \"The dog.\", \"The fox\"]\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(text)\n",
        "\n",
        "print(vectorizer.vocabulary_)\n",
        "print(vectorizer.idf_)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 7, 'quick': 6, 'brown': 0, 'fox': 2, 'jumped': 3, 'over': 5, 'lazy': 4, 'dog': 1}\n",
            "[1.69314718 1.28768207 1.28768207 1.69314718 1.69314718 1.69314718\n",
            " 1.69314718 1.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBMQSUEQrZ_g"
      },
      "source": [
        "##**Transform and print details**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1ioSA8HrTu_",
        "outputId": "cf2966d4-e8e6-4153-e784-e961fbc44a03"
      },
      "source": [
        "vector = vectorizer.transform([text[0]])\n",
        "print(vector.shape)\n",
        "print(vector.toarray())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 8)\n",
            "[[0.36388646 0.27674503 0.27674503 0.36388646 0.36388646 0.36388646\n",
            "  0.36388646 0.42983441]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VqGfIRIrgc2"
      },
      "source": [
        "#**Hashing with HashingVectorizer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqqeiHnprrcP"
      },
      "source": [
        "##**Create hashing transform and print the details**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_F70pzUrYtz",
        "outputId": "de42bf09-7234-48ce-c3b7-5b06ffa6e780"
      },
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "text = [\"The quick brown fox jumped over the lazy dog.\"]\n",
        "\n",
        "vectorizer = HashingVectorizer(n_features=20)\n",
        "vector = vectorizer.transform(text)\n",
        "\n",
        "print(vector.shape)\n",
        "print(vector.toarray())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 20)\n",
            "[[ 0.          0.          0.          0.          0.          0.33333333\n",
            "   0.         -0.33333333  0.33333333  0.          0.          0.33333333\n",
            "   0.          0.          0.         -0.33333333  0.          0.\n",
            "  -0.66666667  0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkgO9lywr2eQ"
      },
      "source": [
        "# **Hands-on Keras**\n",
        "\n",
        "## **Split words using text_to_word_sequence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d43gRGuJrqU9",
        "outputId": "d7b0ed3c-1d00-49f7-c2f7-3fe270bd1a67"
      },
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "text = ' The quick brown fox jumped over the lazy dog. '\n",
        "\n",
        "words = text_to_word_sequence(text)\n",
        "print(words)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSVKbPKRtAYL"
      },
      "source": [
        "##**Find vocabulary size**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2qvUW8Psjyk",
        "outputId": "8813da03-f92f-406e-b320-272901f71fe1"
      },
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "text = ' The quick brown fox jumped over the lazy dog. '\n",
        "\n",
        "words = set(text_to_word_sequence(text))\n",
        "vocab_size = len(words)\n",
        "print(vocab_size)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ8I1Locsusb"
      },
      "source": [
        "##**Encoding with one-hot vector**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEtRqUzes94r",
        "outputId": "77e9e757-c774-4291-db79-fa9269191558"
      },
      "source": [
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "text = ' The quick brown fox jumped over the lazy dog. '\n",
        "\n",
        "words = set(text_to_word_sequence(text))\n",
        "vocab_size = len(words)\n",
        "\n",
        "result = one_hot(text, round(vocab_size * 1.3))\n",
        "print(result)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 7, 7, 3, 4, 5, 3, 4, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eX11JI3trKa"
      },
      "source": [
        "##**Using hashing_trick to hash encode**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuIQbDPVtfAQ",
        "outputId": "02c0f543-098b-4531-d1e5-f2122c86e716"
      },
      "source": [
        "from keras.preprocessing.text import hashing_trick\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "text = ' The quick brown fox jumped over the lazy dog.'\n",
        "words = set(text_to_word_sequence(text))\n",
        "vocab_size = len(words)\n",
        "\n",
        "result = hashing_trick(text, round(vocab_size*1.3), hash_function = 'md5')\n",
        "print(result)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6, 4, 1, 2, 7, 5, 6, 2, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI5a5Q9Jt_Xw"
      },
      "source": [
        "##**Using Tokenizer API and printing details**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbWjZaNzt3Us",
        "outputId": "4cbf7f7b-a488-4d6f-ddea-3bdc1aa18109"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "docs = ['Well done!', 'Good work', 'Great effort', 'nice work', 'Excellent!']\n",
        "\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(docs)\n",
        "\n",
        "print(t.word_counts)\n",
        "print(t.document_count)\n",
        "print(t.word_index)\n",
        "print(t.word_docs)\n",
        "\n",
        "encode_docs = t.texts_to_matrix(docs, mode = 'count')\n",
        "print(encode_docs)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('well', 1), ('done', 1), ('good', 1), ('work', 2), ('great', 1), ('effort', 1), ('nice', 1), ('excellent', 1)])\n",
            "5\n",
            "{'work': 1, 'well': 2, 'done': 3, 'good': 4, 'great': 5, 'effort': 6, 'nice': 7, 'excellent': 8}\n",
            "defaultdict(<class 'int'>, {'done': 1, 'well': 1, 'good': 1, 'work': 2, 'great': 1, 'effort': 1, 'nice': 1, 'excellent': 1})\n",
            "[[0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HQoPSGevdrC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}